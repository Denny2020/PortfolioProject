{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4fbb6a43-bba4-49bc-92c3-8e912d7ffd2a",
   "metadata": {},
   "source": [
    "# ETL PROJECT USING PYTHON AND MYSQL"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f848bb2f-f152-4f09-8615-3d05e9d01f2f",
   "metadata": {},
   "source": [
    "#### In this project, we are going to use python to extract video data from YouTube using YouTube API, then do data transformation, such as ,removing duplacate values, converting data types, filling NANs with 0, droping unwanted columns, extracting date field date field.After transformation, we will connect to our database MYSQL using python-mysql API(mysql.connector), create table in the database,load our data to the database.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "741bb048-08e2-4d74-8b19-6dd3426aa5b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from googleapiclient.discovery import build\n",
    "import pandas as pd\n",
    "from IPython.display import JSON\n",
    "from dateutil import parser\n",
    "import isodate\n",
    "# Data viz packages\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as ticker\n",
    "# NLP\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "from wordcloud import WordCloud\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7bb92166-e446-42b8-ac9e-4db9d18a0176",
   "metadata": {},
   "outputs": [],
   "source": [
    "api_key = 'AIzaSyAE4oq4VNVSH1RtUi-M4dvRHUWW_6klUxI'\n",
    "api_service_name = \"youtube\"\n",
    "api_version = \"v3\"\n",
    "\n",
    "# Get credentials and create an API client\n",
    "youtube = build(\n",
    "    api_service_name, api_version, developerKey=api_key)\n",
    "\n",
    "channel_ids = ['UC7cs8q-gJRlGwj4A8OmCmXg',\n",
    "               #more channel ids\n",
    "              ]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e1267ee-226a-47b4-b609-afd57405feb5",
   "metadata": {},
   "source": [
    "## Extract Data from YouTube using YouTube API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "89dd888c-b602-4dbe-a8a9-269194a6c11f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_channel_stats(youtube, channel_ids):\n",
    "    \n",
    "    \"\"\"\n",
    "    Get channel stats\n",
    "    \n",
    "    Params:\n",
    "    ------\n",
    "    youtube: build object of Youtube API\n",
    "    channel_ids: list of channel IDs\n",
    "    \n",
    "    Returns:\n",
    "    ------\n",
    "    dataframe with all channel stats for each channel ID\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    all_data = []\n",
    "    \n",
    "    request = youtube.channels().list(\n",
    "        part=\"snippet,contentDetails,statistics\",\n",
    "        id=','.join(channel_ids)\n",
    "    )\n",
    "    response = request.execute()\n",
    "\n",
    "    # loop through items\n",
    "    for item in response['items']:\n",
    "        data = {'channelName': item['snippet']['title'],\n",
    "                'subscribers': item['statistics']['subscriberCount'],\n",
    "                'views': item['statistics']['viewCount'],\n",
    "                'totalVideos': item['statistics']['videoCount'],\n",
    "                'playlistId': item['contentDetails']['relatedPlaylists']['uploads']\n",
    "        }\n",
    "        \n",
    "        all_data.append(data)\n",
    "        \n",
    "    return(pd.DataFrame(all_data))\n",
    "\n",
    "playlist_id = \"UU7cs8q-gJRlGwj4A8OmCmXg\"\n",
    "\n",
    "def get_video_ids(youtube, playlist_id):\n",
    "    \n",
    "    video_ids = []\n",
    "    \n",
    "    request = youtube.playlistItems().list(\n",
    "        part=\"snippet,contentDetails\",\n",
    "        playlistId=playlist_id,\n",
    "        maxResults = 50\n",
    "    )\n",
    "    response = request.execute()\n",
    "    \n",
    "    for item in response['items']:\n",
    "        video_ids.append(item['contentDetails']['videoId'])\n",
    "        \n",
    "    next_page_token = response.get('nextPageToken')\n",
    "    while next_page_token is not None:\n",
    "        request = youtube.playlistItems().list(\n",
    "                    part='contentDetails',\n",
    "                    playlistId = playlist_id,\n",
    "                    maxResults = 50,\n",
    "                    pageToken = next_page_token)\n",
    "        response = request.execute()\n",
    "\n",
    "        for item in response['items']:\n",
    "            video_ids.append(item['contentDetails']['videoId'])\n",
    "\n",
    "        next_page_token = response.get('nextPageToken')\n",
    "        \n",
    "    return video_ids\n",
    "    \n",
    "    \n",
    "def get_video_details(youtube, video_ids):\n",
    "\n",
    "    all_video_info = []\n",
    "    \n",
    "    for i in range(0, len(video_ids), 50):\n",
    "        request = youtube.videos().list(\n",
    "            part=\"snippet,contentDetails,statistics\",\n",
    "            id=','.join(video_ids[i:i+50])\n",
    "        )\n",
    "        response = request.execute() \n",
    "\n",
    "        for video in response['items']:\n",
    "            stats_to_keep = {'snippet': ['channelTitle', 'title', 'description', 'tags', 'publishedAt'],\n",
    "                             'statistics': ['viewCount', 'likeCount', 'favouriteCount', 'commentCount'],\n",
    "                             'contentDetails': ['duration', 'definition', 'caption']\n",
    "                            }\n",
    "            video_info = {}\n",
    "            video_info['video_id'] = video['id']\n",
    "\n",
    "            for k in stats_to_keep.keys():\n",
    "                for v in stats_to_keep[k]:\n",
    "                    try:\n",
    "                        video_info[v] = video[k][v]\n",
    "                    except:\n",
    "                        video_info[v] = None\n",
    "\n",
    "            all_video_info.append(video_info)\n",
    "    \n",
    "    return pd.DataFrame(all_video_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4a600a7c-1a25-4a04-8a7d-effc17b243d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "184\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>video_id</th>\n",
       "      <th>channelTitle</th>\n",
       "      <th>title</th>\n",
       "      <th>description</th>\n",
       "      <th>tags</th>\n",
       "      <th>publishedAt</th>\n",
       "      <th>viewCount</th>\n",
       "      <th>likeCount</th>\n",
       "      <th>favouriteCount</th>\n",
       "      <th>commentCount</th>\n",
       "      <th>duration</th>\n",
       "      <th>definition</th>\n",
       "      <th>caption</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0MKcCHrTo0c</td>\n",
       "      <td>Alex The Analyst</td>\n",
       "      <td>Reading, Writing, and Appending Files in Pytho...</td>\n",
       "      <td>In this series we will be walking through ever...</td>\n",
       "      <td>[Data Analyst, Data Analyst job, Data Analyst ...</td>\n",
       "      <td>2022-12-27T13:00:00Z</td>\n",
       "      <td>2517</td>\n",
       "      <td>104</td>\n",
       "      <td>None</td>\n",
       "      <td>7</td>\n",
       "      <td>PT9M24S</td>\n",
       "      <td>hd</td>\n",
       "      <td>false</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>bVJfQAe-UP4</td>\n",
       "      <td>Alex The Analyst</td>\n",
       "      <td>Why I Quit my 125k Analytics Job</td>\n",
       "      <td>This is not where I saw my career going, but h...</td>\n",
       "      <td>[Data Analyst, Data Analyst job, Data Analyst ...</td>\n",
       "      <td>2022-12-20T12:00:33Z</td>\n",
       "      <td>77221</td>\n",
       "      <td>4734</td>\n",
       "      <td>None</td>\n",
       "      <td>716</td>\n",
       "      <td>PT7M43S</td>\n",
       "      <td>hd</td>\n",
       "      <td>false</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>_2OknmkngkQ</td>\n",
       "      <td>Alex The Analyst</td>\n",
       "      <td>Data Analyst Q/A Livestream + Special Guest! |...</td>\n",
       "      <td>This is December's Livestream where you can co...</td>\n",
       "      <td>[Data Analyst, Data Analyst job, Data Analyst ...</td>\n",
       "      <td>2022-12-17T14:16:05Z</td>\n",
       "      <td>3935</td>\n",
       "      <td>153</td>\n",
       "      <td>None</td>\n",
       "      <td>16</td>\n",
       "      <td>PT1H22M48S</td>\n",
       "      <td>hd</td>\n",
       "      <td>false</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>B63bN2cLVLM</td>\n",
       "      <td>Alex The Analyst</td>\n",
       "      <td>Converting Data Types in Python | Python for B...</td>\n",
       "      <td>In this series we will be walking through ever...</td>\n",
       "      <td>[Data Analyst, Data Analyst job, Data Analyst ...</td>\n",
       "      <td>2022-12-13T12:00:06Z</td>\n",
       "      <td>2664</td>\n",
       "      <td>93</td>\n",
       "      <td>None</td>\n",
       "      <td>21</td>\n",
       "      <td>PT6M36S</td>\n",
       "      <td>hd</td>\n",
       "      <td>false</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>zvzjaqMBEso</td>\n",
       "      <td>Alex The Analyst</td>\n",
       "      <td>Functions in Python | Python for Beginners</td>\n",
       "      <td>In this series we will be walking through ever...</td>\n",
       "      <td>[Data Analyst, Data Analyst job, Data Analyst ...</td>\n",
       "      <td>2022-12-06T12:00:36Z</td>\n",
       "      <td>3258</td>\n",
       "      <td>134</td>\n",
       "      <td>None</td>\n",
       "      <td>22</td>\n",
       "      <td>PT12M44S</td>\n",
       "      <td>hd</td>\n",
       "      <td>false</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>179</th>\n",
       "      <td>4rfr6A3lO-Y</td>\n",
       "      <td>Alex The Analyst</td>\n",
       "      <td>Data Analyst Resume | Reviewing My Resume! | F...</td>\n",
       "      <td>Data Analyst Resume | Reviewing My Resume! | F...</td>\n",
       "      <td>[Data Analyst, How to become a data analyst, D...</td>\n",
       "      <td>2020-01-30T14:07:55Z</td>\n",
       "      <td>57304</td>\n",
       "      <td>1435</td>\n",
       "      <td>None</td>\n",
       "      <td>63</td>\n",
       "      <td>PT7M33S</td>\n",
       "      <td>hd</td>\n",
       "      <td>false</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>180</th>\n",
       "      <td>OTq2NRy_AGs</td>\n",
       "      <td>Alex The Analyst</td>\n",
       "      <td>Working at a Big Company Vs Small Company | To...</td>\n",
       "      <td>Working at a Big Company Vs Small Company | To...</td>\n",
       "      <td>[Data Analyst, How to become a Data Analyst, B...</td>\n",
       "      <td>2020-01-25T16:38:39Z</td>\n",
       "      <td>12400</td>\n",
       "      <td>353</td>\n",
       "      <td>None</td>\n",
       "      <td>20</td>\n",
       "      <td>PT5M50S</td>\n",
       "      <td>hd</td>\n",
       "      <td>false</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>181</th>\n",
       "      <td>ya28cb3zFGE</td>\n",
       "      <td>Alex The Analyst</td>\n",
       "      <td>Data Analyst Salary | 100k with No Experience</td>\n",
       "      <td>Data Analyst Salary | 100k with No Experience ...</td>\n",
       "      <td>[Data Analyst Salary, Data analyst with no exp...</td>\n",
       "      <td>2020-01-23T03:16:09Z</td>\n",
       "      <td>54015</td>\n",
       "      <td>1934</td>\n",
       "      <td>None</td>\n",
       "      <td>218</td>\n",
       "      <td>PT5M3S</td>\n",
       "      <td>hd</td>\n",
       "      <td>false</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>182</th>\n",
       "      <td>Hsi2BG0SOiQ</td>\n",
       "      <td>Alex The Analyst</td>\n",
       "      <td>Truth About Big Companies | Told by a Fortune ...</td>\n",
       "      <td>Truth About Big Companies // There are a ton o...</td>\n",
       "      <td>[Working at a big company, Big company data an...</td>\n",
       "      <td>2020-01-21T03:52:15Z</td>\n",
       "      <td>6725</td>\n",
       "      <td>264</td>\n",
       "      <td>None</td>\n",
       "      <td>17</td>\n",
       "      <td>PT5M45S</td>\n",
       "      <td>hd</td>\n",
       "      <td>false</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>183</th>\n",
       "      <td>6lQzbk6_OTw</td>\n",
       "      <td>Alex The Analyst</td>\n",
       "      <td>Top 3 Data Analyst Skills in 2020</td>\n",
       "      <td>Top 3 Data Analyst Skills in 2020 // There are...</td>\n",
       "      <td>[Top skills for data analyst, Top 3 skills for...</td>\n",
       "      <td>2020-01-17T14:31:39Z</td>\n",
       "      <td>25062</td>\n",
       "      <td>1257</td>\n",
       "      <td>None</td>\n",
       "      <td>137</td>\n",
       "      <td>PT2M40S</td>\n",
       "      <td>hd</td>\n",
       "      <td>false</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>184 rows Ã— 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        video_id      channelTitle  \\\n",
       "0    0MKcCHrTo0c  Alex The Analyst   \n",
       "1    bVJfQAe-UP4  Alex The Analyst   \n",
       "2    _2OknmkngkQ  Alex The Analyst   \n",
       "3    B63bN2cLVLM  Alex The Analyst   \n",
       "4    zvzjaqMBEso  Alex The Analyst   \n",
       "..           ...               ...   \n",
       "179  4rfr6A3lO-Y  Alex The Analyst   \n",
       "180  OTq2NRy_AGs  Alex The Analyst   \n",
       "181  ya28cb3zFGE  Alex The Analyst   \n",
       "182  Hsi2BG0SOiQ  Alex The Analyst   \n",
       "183  6lQzbk6_OTw  Alex The Analyst   \n",
       "\n",
       "                                                 title  \\\n",
       "0    Reading, Writing, and Appending Files in Pytho...   \n",
       "1                     Why I Quit my 125k Analytics Job   \n",
       "2    Data Analyst Q/A Livestream + Special Guest! |...   \n",
       "3    Converting Data Types in Python | Python for B...   \n",
       "4           Functions in Python | Python for Beginners   \n",
       "..                                                 ...   \n",
       "179  Data Analyst Resume | Reviewing My Resume! | F...   \n",
       "180  Working at a Big Company Vs Small Company | To...   \n",
       "181      Data Analyst Salary | 100k with No Experience   \n",
       "182  Truth About Big Companies | Told by a Fortune ...   \n",
       "183                  Top 3 Data Analyst Skills in 2020   \n",
       "\n",
       "                                           description  \\\n",
       "0    In this series we will be walking through ever...   \n",
       "1    This is not where I saw my career going, but h...   \n",
       "2    This is December's Livestream where you can co...   \n",
       "3    In this series we will be walking through ever...   \n",
       "4    In this series we will be walking through ever...   \n",
       "..                                                 ...   \n",
       "179  Data Analyst Resume | Reviewing My Resume! | F...   \n",
       "180  Working at a Big Company Vs Small Company | To...   \n",
       "181  Data Analyst Salary | 100k with No Experience ...   \n",
       "182  Truth About Big Companies // There are a ton o...   \n",
       "183  Top 3 Data Analyst Skills in 2020 // There are...   \n",
       "\n",
       "                                                  tags           publishedAt  \\\n",
       "0    [Data Analyst, Data Analyst job, Data Analyst ...  2022-12-27T13:00:00Z   \n",
       "1    [Data Analyst, Data Analyst job, Data Analyst ...  2022-12-20T12:00:33Z   \n",
       "2    [Data Analyst, Data Analyst job, Data Analyst ...  2022-12-17T14:16:05Z   \n",
       "3    [Data Analyst, Data Analyst job, Data Analyst ...  2022-12-13T12:00:06Z   \n",
       "4    [Data Analyst, Data Analyst job, Data Analyst ...  2022-12-06T12:00:36Z   \n",
       "..                                                 ...                   ...   \n",
       "179  [Data Analyst, How to become a data analyst, D...  2020-01-30T14:07:55Z   \n",
       "180  [Data Analyst, How to become a Data Analyst, B...  2020-01-25T16:38:39Z   \n",
       "181  [Data Analyst Salary, Data analyst with no exp...  2020-01-23T03:16:09Z   \n",
       "182  [Working at a big company, Big company data an...  2020-01-21T03:52:15Z   \n",
       "183  [Top skills for data analyst, Top 3 skills for...  2020-01-17T14:31:39Z   \n",
       "\n",
       "    viewCount likeCount favouriteCount commentCount    duration definition  \\\n",
       "0        2517       104           None            7     PT9M24S         hd   \n",
       "1       77221      4734           None          716     PT7M43S         hd   \n",
       "2        3935       153           None           16  PT1H22M48S         hd   \n",
       "3        2664        93           None           21     PT6M36S         hd   \n",
       "4        3258       134           None           22    PT12M44S         hd   \n",
       "..        ...       ...            ...          ...         ...        ...   \n",
       "179     57304      1435           None           63     PT7M33S         hd   \n",
       "180     12400       353           None           20     PT5M50S         hd   \n",
       "181     54015      1934           None          218      PT5M3S         hd   \n",
       "182      6725       264           None           17     PT5M45S         hd   \n",
       "183     25062      1257           None          137     PT2M40S         hd   \n",
       "\n",
       "    caption  \n",
       "0     false  \n",
       "1     false  \n",
       "2     false  \n",
       "3     false  \n",
       "4     false  \n",
       "..      ...  \n",
       "179   false  \n",
       "180   false  \n",
       "181   false  \n",
       "182   false  \n",
       "183   false  \n",
       "\n",
       "[184 rows x 13 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "channel_stat = get_channel_stats(youtube, channel_ids)\n",
    "channel_stat\n",
    "\n",
    "video_ids = get_video_ids(youtube, playlist_id)\n",
    "print(len(video_ids))\n",
    "\n",
    "video_df = get_video_details(youtube, video_ids)\n",
    "video_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95a23957-e891-432c-9eb1-01691528f888",
   "metadata": {},
   "source": [
    "## Transform the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "babf125d-6e65-44b6-9163-2e5662a49a17",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "video_id          False\n",
       "channelTitle      False\n",
       "title             False\n",
       "description       False\n",
       "tags               True\n",
       "publishedAt       False\n",
       "viewCount         False\n",
       "likeCount         False\n",
       "favouriteCount     True\n",
       "commentCount      False\n",
       "duration          False\n",
       "definition        False\n",
       "caption           False\n",
       "dtype: bool"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Check for null values\n",
    "video_df.isnull().any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "269cab7b-d9d2-415e-9e10-4dedec9b8b11",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "video_id                           object\n",
       "channelTitle                       object\n",
       "title                              object\n",
       "description                        object\n",
       "tags                               object\n",
       "publishedAt       datetime64[ns, tzutc()]\n",
       "Total_Views                       float64\n",
       "Total_likes                       float64\n",
       "favouriteCount                    float64\n",
       "Total_Comment                     float64\n",
       "duration                           object\n",
       "definition                         object\n",
       "caption                            object\n",
       "pushblish Day                      object\n",
       "durationSecs                      float64\n",
       "tagCount                            int64\n",
       "pushblishDate                      object\n",
       "dtype: object"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Check datatypes\n",
    "video_df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a4cb7b19-7a7e-4a98-af71-bd7bb6007a6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert count columns to numeric\n",
    "numeric_cols = ['viewCount', 'likeCount', 'favouriteCount', 'commentCount']\n",
    "video_df[numeric_cols] = video_df[numeric_cols].apply(pd.to_numeric, errors = 'coerce', axis = 1)\n",
    "\n",
    "# Publish day in the week\n",
    "video_df['publishedAt'] = video_df['publishedAt'].apply(lambda x: parser.parse(x)) \n",
    "video_df['pushblishDayName'] = video_df['publishedAt'].apply(lambda x: x.strftime(\"%A\")) \n",
    "\n",
    "# convert duration to seconds\n",
    "import isodate\n",
    "video_df['durationSecs'] = video_df['duration'].apply(lambda x: isodate.parse_duration(x))\n",
    "video_df['durationSecs'] = video_df['durationSecs'].astype('timedelta64[s]')\n",
    "\n",
    "# Add tag count\n",
    "video_df['tagCount'] = video_df['tags'].apply(lambda x: 0 if x is None else len(x))\n",
    "\n",
    "# Rename some columns\n",
    "video_df.rename(columns={'viewCount': 'Total_Views', 'likeCount': 'Total_likes',\n",
    "                         'commentCount': 'Total_Comment','pushblishDayName':'pushblish Day'},inplace=True)\n",
    "# convert date \n",
    "video_df['pushblishDate'] = video_df['publishedAt'].apply(lambda x: x.strftime(\"%Y-%m-%d %H:%M:%S\")) \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2180ead2-89a4-49d0-aaba-a8ccf744dd26",
   "metadata": {},
   "outputs": [],
   "source": [
    "transformed_df = video_df.drop(columns=['duration','description','publishedAt'])\n",
    "\n",
    "transformed_df = transformed_df.fillna(0)\n",
    "\n",
    "# convert Total_Views, Total_likes,favouriteCount,Total_Comment and durationSecs columns from float to int data type\n",
    "transformed_df[\"Total_Views\"] = transformed_df[\"Total_Views\"].astype('int64')\n",
    "transformed_df[\"Total_likes\"] = transformed_df[\"Total_likes\"].astype('int64')\n",
    "transformed_df[\"favouriteCount\"] = transformed_df[\"favouriteCount\"].astype('int64')\n",
    "transformed_df[\"Total_Comment\"] = transformed_df[\"Total_Comment\"].astype('int64')\n",
    "transformed_df[\"durationSecs\"] = transformed_df[\"durationSecs\"].astype('int64')\n",
    "\n",
    "transformed_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb3941b8-89ad-487e-b24a-1e0e90610e93",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write the data to cv file for further analysis\n",
    "\n",
    "transformed_df.to_csv(\"AlexVideoDs.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fde87b2-4395-4c1f-be1f-9855fd2b20fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "transformed_df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20b81b56-d0fd-4189-9112-5dea44247c92",
   "metadata": {},
   "source": [
    "## Load Data to Database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "0eb012fa-b7e0-4aa6-8d8c-8b17c564e4ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "import mysql.connector\n",
    "from mysql.connector import Error\n",
    "\n",
    "# Connect to the database\n",
    "try:\n",
    "    conn = mysql.connector.connect(\n",
    "    host='localhost',\n",
    "    user='root',\n",
    "    password='password',\n",
    "    database='PortfolioProjects'\n",
    "    )\n",
    "    cursor = conn.cursor()\n",
    "    \n",
    "    # Drop table if exists\n",
    "    cursor.execute('DROP TABLE IF EXISTS videoDS;')\n",
    "    \n",
    "    # Create the table\n",
    "    cursor.execute('''\n",
    "    CREATE TABLE IF NOT EXISTS videoDS(\n",
    "        video_id VARCHAR(20),\n",
    "        channelTitle VARCHAR(30),\n",
    "        title VARCHAR(200),\n",
    "        tags VARCHAR(1000),\n",
    "        Total_Views long,\n",
    "        Total_likes long,\n",
    "        favouriteCount long,\n",
    "        Total_Comment long,\n",
    "        definition CHAR(5),\n",
    "        caption VARCHAR(10),\n",
    "        pushblishDay VARCHAR(15),\n",
    "        durationSecs long,\n",
    "        tagCount long,\n",
    "        pushblishDate long)\n",
    "        ''')\n",
    "    \n",
    "    # Read data from the CSV file\n",
    "    with open('AlexVideoDs.csv', 'r') as f:\n",
    "        reader = csv.reader(f)\n",
    "        next(reader)  # Skip the header row\n",
    "        for row in reader:\n",
    "            # Insert the data into the table\n",
    "            cursor.execute('INSERT INTO videoDS(video_id, \\\n",
    "            channelTitle,title,tags,\\\n",
    "            Total_Views,Total_likes,favouriteCount,Total_Comment,definition,\\\n",
    "            caption,pushblishDay,durationSecs,tagCount,pushblishDate)' \\\n",
    "                           'VALUES(\"%s\",\"%s\",\"%s\", \"%s\", \"%s\",\"%s\", \"%s\", \"%s\",\"%s\", \"%s\", \"%s\",\"%s\", \"%s\", \"%s\")',row)\n",
    "except Error as e:\n",
    "    print(\"Error while connecting to MySQL\", e)\n",
    "\n",
    "# Save the changes and close the connection\n",
    "conn.commit()\n",
    "conn.close()\n",
    "print(\"Done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "104e86c9-05c4-4125-afca-15d85126d809",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Alternatively, we can load the datafram straight to the database without writing it to csv first.\n",
    "#import pymysql\n",
    "#from sqlalchemy import create_engine\n",
    "\n",
    "# create sqlalchemy engine\n",
    "# engine = create_engine(\"mysql+pymysql://{user}:{pw}@localhost/{db}\"\n",
    "                       #.format(user=\"root\",\n",
    "                              # pw=\"password\",\n",
    "                               #db=\"databasename\"))\n",
    "\n",
    "#transformed_df.to_sql('movie_details', con = engine, if_exists = 'append', chunksize = 1000)\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7666a071-74ca-48a5-bbe9-74b93065063e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
